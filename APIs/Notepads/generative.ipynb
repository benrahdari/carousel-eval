{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67fe010e-191c-4b2e-8f87-df1eac36c507",
   "metadata": {},
   "source": [
    "## Original Generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b5abd9a-a33c-481f-93a7-efc8c61b365f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the distilgpt2 model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cbfa1d9cb5d451089e3e0e5b3ab33b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing tags:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating title for tags: ['chocolate', 'cake', 'easy']\n",
      "Encoding the prompt...\n",
      "Generating title from the model...\n",
      "Decoding the generated title...\n",
      "Generated Title: \n",
      "---------------------------------------------------\n",
      "\n",
      "Generating title for tags: ['chicken', 'spicy', 'grilled']\n",
      "Encoding the prompt...\n",
      "Generating title from the model...\n",
      "Decoding the generated title...\n",
      "Generated Title: \n",
      "---------------------------------------------------\n",
      "\n",
      "Generating title for tags: ['vegetarian', 'healthy', 'salad']\n",
      "Encoding the prompt...\n",
      "Generating title from the model...\n",
      "Decoding the generated title...\n",
      "Generated Title: \n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"distilgpt2\"\n",
    "print(f\"Loading the {model_name} model and tokenizer...\")\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Function to generate title based on tags\n",
    "def generate_title(tags):\n",
    "    # Prepare a prompt for the model using the aggregated tags\n",
    "    prompt = f\"Write a title for recipes that mainly involve {', '.join(tags[:-1])}, and {tags[-1]}.\"\n",
    "    \n",
    "    # Encode the prompt to tensor\n",
    "    print(\"Encoding the prompt...\")\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate text from the model using beam search\n",
    "    print(\"Generating title from the model...\")\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids, \n",
    "            max_length=100, \n",
    "            num_return_sequences=1, \n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            num_beams=5,\n",
    "            early_stopping=True\n",
    "        )\n",
    "    \n",
    "    # Decode the generated text\n",
    "    print(\"Decoding the generated title...\")\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract only the generated portion (excluding the prompt)\n",
    "    generated_title = generated_text.replace(prompt, \"\").strip()\n",
    "    return generated_title\n",
    "\n",
    "# Example with tqdm progress bar\n",
    "tags_list = [[\"chocolate\", \"cake\", \"easy\"], [\"chicken\", \"spicy\", \"grilled\"], [\"vegetarian\", \"healthy\", \"salad\"]]\n",
    "for tags in tqdm(tags_list, desc=\"Processing tags\"):\n",
    "    print(f\"\\nGenerating title for tags: {tags}\")\n",
    "    title = generate_title(tags)\n",
    "    print(f\"Generated Title: {title}\")\n",
    "    print(\"---------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe7855f-c315-4359-817a-4576c628123e",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5586a44-f9dc-4127-892a-d8a9c009914e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the sshleifer/distilbart-cnn-12-6 model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c423c74c79f14452abc7c2d190595937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing tags:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating title for tags: ['chocolate', 'cake', 'easy']\n",
      "Generating title from the model...\n",
      "Decoding the generated title...\n",
      "Generated Title:  Write a title for recipes that mainly involve chocolate, cake, and easy. Write one title for a recipe that mainly involves chocolate and cake. Do you know a recipe for easy chocolate recipes? Share it with us on Facebook and Twitter @mailonline.com for more information.\n",
      "---------------------------------------------------\n",
      "\n",
      "Generating title for tags: ['chicken', 'spicy', 'grilled']\n",
      "Generating title from the model...\n",
      "Decoding the generated title...\n",
      "Generated Title:  Write a title for recipes that mainly involve chicken, spicy, and grilled. Include recipes that involve chicken and spicy, such as grilled chicken or spicy chicken. Use this title to help you create a new recipe for a new cookbook called \"Chilli Grilled\" The title is based on recipes that include chicken and grilled chicken.\n",
      "---------------------------------------------------\n",
      "\n",
      "Generating title for tags: ['vegetarian', 'healthy', 'salad']\n",
      "Generating title from the model...\n",
      "Decoding the generated title...\n",
      "Generated Title:  Write a title for recipes that mainly involve vegetarian, healthy, and salad. The title is based on recipes that involve vegetables, healthy and salad. Write it as a title that includes healthy, healthy recipes. For more recipes, visit www.dailymailonline.co.uk for more information.\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"sshleifer/distilbart-cnn-12-6\"\n",
    "print(f\"Loading the {model_name} model and tokenizer...\")\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Function to generate title based on tags\n",
    "def generate_title(tags):\n",
    "    # Prepare a prompt for the model using the aggregated tags\n",
    "    prompt = f\"Write a title for recipes that mainly involve {', '.join(tags[:-1])}, and {tags[-1]}.\"\n",
    "    \n",
    "    # Generate summary from the model\n",
    "    print(\"Generating title from the model...\")\n",
    "    with torch.no_grad():\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).input_ids\n",
    "        summary_ids = model.generate(input_ids, max_length=100, num_beams=5, length_penalty=2.0, early_stopping=True)\n",
    "\n",
    "    \n",
    "    # Decode the generated text\n",
    "    print(\"Decoding the generated title...\")\n",
    "    generated_title = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return generated_title\n",
    "\n",
    "# Example with tqdm progress bar\n",
    "tags_list = [[\"chocolate\", \"cake\", \"easy\"], [\"chicken\", \"spicy\", \"grilled\"], [\"vegetarian\", \"healthy\", \"salad\"]]\n",
    "for tags in tqdm(tags_list, desc=\"Processing tags\"):\n",
    "    print(f\"\\nGenerating title for tags: {tags}\")\n",
    "    title = generate_title(tags)\n",
    "    print(f\"Generated Title: {title}\")\n",
    "    print(\"---------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cdee51-2067-4c4b-aef1-38043b79f230",
   "metadata": {},
   "source": [
    "## Summarization Improved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5732109f-e1e9-41eb-877d-7871be2318bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the sshleifer/distilbart-cnn-12-6 model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a20efaab0a430e896ef96b4ad078cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing tags:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating title for tags: [('chocolate', 0.9), ('cake', 0.8), ('easy', 0.7)]\n",
      "Generating title from the model...\n",
      "Decoding the generated title...\n",
      "Generated Title:  Summarize recipes with the following attributes in three words: chocolate, cake, and easy.\n",
      "---------------------------------------------------\n",
      "\n",
      "Generating title for tags: [('chicken', 0.9), ('spicy', 0.8), ('grilled', 0.7)]\n",
      "Generating title from the model...\n",
      "Decoding the generated title...\n",
      "Generated Title:  Summarize recipes with the following attributes in three words: chicken, spicy, and grilled.\n",
      "---------------------------------------------------\n",
      "\n",
      "Generating title for tags: [('vegetarian', 0.9), ('healthy', 0.8), ('salad', 0.7)]\n",
      "Generating title from the model...\n",
      "Decoding the generated title...\n",
      "Generated Title:  Summarize recipes with the following attributes in three words: vegetarian, healthy, and salad.\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"sshleifer/distilbart-cnn-12-6\"\n",
    "print(f\"Loading the {model_name} model and tokenizer...\")\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Rank tags based on their scores\n",
    "def rank_tags(tags_data):\n",
    "    tag_scores = defaultdict(float)\n",
    "    tag_counts = defaultdict(int)\n",
    "    \n",
    "    for tag, score in tags_data:\n",
    "        tag_scores[tag] += score\n",
    "        tag_counts[tag] += 1\n",
    "        \n",
    "    # Average the scores\n",
    "    for tag in tag_scores:\n",
    "        tag_scores[tag] /= tag_counts[tag]\n",
    "        \n",
    "    # Sort tags based on scores\n",
    "    sorted_tags = sorted(tag_scores.keys(), key=lambda x: tag_scores[x], reverse=True)\n",
    "    \n",
    "    return sorted_tags[:3]  # Take top 3 tags\n",
    "\n",
    "# Function to generate title based on tags\n",
    "def generate_title(tags):\n",
    "    top_tags = rank_tags(tags)\n",
    "    \n",
    "    # Refined prompt\n",
    "    prompt = f\"Summarize recipes with the following attributes in three words: {', '.join(top_tags[:-1])}, and {top_tags[-1]}.\"\n",
    "    \n",
    "    print(\"Generating title from the model...\")\n",
    "    with torch.no_grad():\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).input_ids\n",
    "        summary_ids = model.generate(input_ids, \n",
    "                                     max_length=50,\n",
    "                                     min_length=5,  # Explicitly set the minimum length\n",
    "                                     num_beams=5, \n",
    "                                     length_penalty=2.0, \n",
    "                                     early_stopping=True,\n",
    "                                     temperature=0.8,  # Adjust temperature\n",
    "                                     top_k=20)  # Adjust top_k\n",
    "    \n",
    "    # Decode the generated text\n",
    "    print(\"Decoding the generated title...\")\n",
    "    generated_title = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return generated_title\n",
    "\n",
    "# Example with tqdm progress bar\n",
    "tags_data = [[('chocolate', 0.9), ('cake', 0.8), ('easy', 0.7)],\n",
    "             [('chicken', 0.9), ('spicy', 0.8), ('grilled', 0.7)],\n",
    "             [('vegetarian', 0.9), ('healthy', 0.8), ('salad', 0.7)]]\n",
    "\n",
    "for tags in tqdm(tags_data, desc=\"Processing tags\"):\n",
    "    print(f\"\\nGenerating title for tags: {tags}\")\n",
    "    title = generate_title(tags)\n",
    "    print(f\"Generated Title: {title}\")\n",
    "    print(\"---------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e7ac6b-f94e-4ae4-884c-beb8165c2fa4",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7fc66dc-e202-4346-badf-ad881839d392",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the sshleifer/distilbart-cnn-12-6 model and tokenizer...\n",
      "\n",
      "Generating title for aggregated tags from 10 recipes:\n",
      "All tags =  [('Pasta Primavera', 0.65137124), ('Homemade Pasta', 0.6164523), ('Pasta Salads', 0.60546464), ('Ravioli', 0.5996085), ('Chicken Salads', 0.5977807), ('Flan', 0.59315884), ('Chocolate Fudge', 0.53663886), ('Spanish Rice', 0.50429004), ('Cheese Fondue', 0.47348017), ('Chicken Cacciatore', 0.47016305), ('Pulled Pork', 0.6835002), ('Pork Tenderloin', 0.5930016), ('Pork Shoulder', 0.5721208), ('Ground Pork', 0.57033366), ('Pork Ribs', 0.5457189), (\"Shepherd's Pie\", 0.75314134), ('Sweet Potato Pie', 0.59521466), ('Mincemeat Pie', 0.59072185), ('Apple Pie', 0.5759548), ('Rhubarb Pie', 0.5733078), ('Rhubarb Pie', 0.6407865), ('Creme Brulee', 0.5217254), (\"Shepherd's Pie\", 0.5121667), ('Breakfast Casseroles', 0.50978476), ('Blueberry Pie', 0.5065649), ('Panini', 0.50231516), ('Casseroles', 0.4743449), ('Rice Casseroles', 0.4580714), ('Breakfast Casseroles', 0.45668033), ('Noodle Casseroles', 0.44852918), ('Sweet Potato Pie', 0.6214342), ('Pot Pies', 0.6160767), ('Mincemeat Pie', 0.5869349), ('Apple Pie', 0.5788018), ('Pecan Pie', 0.5638401), ('Rhubarb Pie', 0.5454418), ('French Toast', 0.5245203), (\"Shepherd's Pie\", 0.5230413), ('Pavlovas', 0.51718855), ('Breakfast Casseroles', 0.5036762), ('Sandwiches', 0.66423404), ('Fajitas', 0.5789384), ('Quesadillas', 0.5768902), ('Breakfast Burritos', 0.5716133), ('Ground Turkey', 0.56918883), ('Passover', 0.6691374), ('Seder', 0.5180576), ('Cooking for Two', 0.43955112), ('Potluck Recipes', 0.42114103), ('Casseroles', 0.41368636)]\n",
      "Top Tags = ['Pulled Pork', 'Passover', 'Sandwiches']\n",
      "Distill the culinary essence of dishes starring: Pulled Pork, Passover, and Sandwiches into a three-word snapshot.\n",
      "Generating title from the model...\n",
      "Decoding the generated title...\n",
      "Generated Title:  Pulled Pork, Passover, and Sandwiches are a three-word snapshot of the dishes.\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"sshleifer/distilbart-cnn-12-6\"\n",
    "print(f\"Loading the {model_name} model and tokenizer...\")\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Rank tags based on their scores\n",
    "def rank_tags(tags_data):\n",
    "    tag_scores = defaultdict(float)\n",
    "    tag_counts = defaultdict(int)\n",
    "    \n",
    "    for tag, score in tags_data:\n",
    "        tag_scores[tag] += score\n",
    "        tag_counts[tag] += 1\n",
    "        \n",
    "    # Average the scores\n",
    "    for tag in tag_scores:\n",
    "        tag_scores[tag] /= tag_counts[tag]\n",
    "        \n",
    "    # Sort tags based on scores\n",
    "    sorted_tags = sorted(tag_scores.keys(), key=lambda x: tag_scores[x], reverse=True)\n",
    "    \n",
    "    return sorted_tags[:3]  # Take top 3 tags\n",
    "\n",
    "# Function to generate title based on tags\n",
    "def generate_title(tags):\n",
    "    top_tags = rank_tags(tags)\n",
    "    \n",
    "    print(f\"Top Tags = {top_tags}\")\n",
    "    \n",
    "    # Refined prompt\n",
    "    #prompt = f\"Summarize recipes with the following attributes in three words: {', '.join(top_tags[:-1])}, and {top_tags[-1]}.\"\n",
    "    \n",
    "    #1\n",
    "    #prompt = f\"Provide a three-word essence of recipes featuring: {', '.join(top_tags[:-1])}, and {top_tags[-1]}.\"\n",
    "    #2\n",
    "    #prompt = f\"In just three words, capture the spirit of recipes that incorporate: {', '.join(top_tags[:-1])}, and {top_tags[-1]}.\"  \n",
    "    #3\n",
    "    #prompt = f\"Give a three-word snapshot of dishes primarily using: {', '.join(top_tags[:-1])}, and {top_tags[-1]}.\"    \n",
    "    #4\n",
    "    #prompt = f\"Encapsulate in three words the core of recipes centered around: {', '.join(top_tags[:-1])}, and {top_tags[-1]}.\"\n",
    "    #5\n",
    "    #prompt = f\"Boil down the essence of recipes highlighting: {', '.join(top_tags[:-1])}, and {top_tags[-1]} into three words.\"\n",
    "    #6\n",
    "    #prompt = f\"How would you describe in three words the dishes that are rich in: {', '.join(top_tags[:-1])}, and {top_tags[-1]}?\"\n",
    "    #7\n",
    "    #prompt = f\"If you had to pick three words to represent recipes with: {', '.join(top_tags[:-1])}, and {top_tags[-1]}, what would they be?\"\n",
    "    #8\n",
    "    #prompt = f\"Capture the main theme of recipes that include: {', '.join(top_tags[:-1])}, and {top_tags[-1]} in just three words.\"\n",
    "    #9\n",
    "    #prompt = f\"Give a brief three-word overview of dishes that are all about: {', '.join(top_tags[:-1])}, and {top_tags[-1]}.\"  \n",
    "    #10\n",
    "    prompt = f\"Distill the culinary essence of dishes starring: {', '.join(top_tags[:-1])}, and {top_tags[-1]} into a three-word snapshot.\"    \n",
    "    \n",
    "    \n",
    "    print(prompt)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"Generating title from the model...\")\n",
    "    with torch.no_grad():\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).input_ids\n",
    "        summary_ids = model.generate(input_ids, \n",
    "                                     max_length=50,\n",
    "                                     min_length=5,\n",
    "                                     num_beams=5, \n",
    "                                     length_penalty=2.0, \n",
    "                                     early_stopping=True,\n",
    "                                     temperature=1.2,\n",
    "                                     top_k=30,\n",
    "                                     top_p=0.95)\n",
    "    \n",
    "    # Decode the generated text\n",
    "    print(\"Decoding the generated title...\")\n",
    "    generated_title = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return generated_title\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"examples.csv\")\n",
    "\n",
    "def process_row(row):\n",
    "    # Extract classes and scores\n",
    "    classes = row[\"Predicted Classes\"].split(\", \")\n",
    "    scores = list(map(float, row[\"Raw Similarity Scores\"].split(\", \")))\n",
    "    \n",
    "    # Pair classes with scores\n",
    "    tags_scores = list(zip(classes, scores))\n",
    "    \n",
    "    return tags_scores\n",
    "\n",
    "# Process the DataFrame to get paired classes and scores\n",
    "df[\"Tags\"] = df.apply(process_row, axis=1)\n",
    "\n",
    "# Randomly select 10 recipes\n",
    "selected_recipes = df.sample(10)\n",
    "\n",
    "# Aggregate tags from selected recipes\n",
    "all_tags = []\n",
    "for _, row in selected_recipes.iterrows():\n",
    "    all_tags.extend(row[\"Tags\"])\n",
    "\n",
    "# Generate title using aggregated tags\n",
    "print(\"\\nGenerating title for aggregated tags from 10 recipes:\")\n",
    "print(f\"All tags =  {all_tags}\")\n",
    "title = generate_title(all_tags)\n",
    "print(f\"Generated Title: {title}\")\n",
    "print(\"---------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570f9dd8-0ffa-408a-a9ef-c1e6ef3c2e8c",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "759194dc-8e7d-4fac-af8d-f135839bf42f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the gpt2-medium model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating title for aggregated tags from 10 recipes:\n",
      "All tags =  [('Turkey Brines', 0.47434875), ('Beef Tenderloin', 0.4702204), ('Filet Mignon', 0.46177846), ('Pork Tenderloin', 0.44696778), ('Beef Stews', 0.41616905), ('Brownies', 0.65157694), ('Peanut Butter Cookies', 0.5190474), ('Chocolate Fudge', 0.51230067), ('Chocolate Cakes', 0.50989646), ('Breakfast Casseroles', 0.48654664), ('Quinoa', 0.52076924), ('Chilaquiles', 0.51118153), ('Fruit Salads', 0.49696106), ('Cranberry Sauces', 0.45759338), ('Key Lime Pie', 0.4526069), ('Chicken Salads', 0.5600661), ('Chicken and Dumplings', 0.5522183), ('Buffalo Chicken Dips', 0.5382873), ('Chicken Noodle Soups', 0.5198916), ('Ground Chicken', 0.5193598), ('Spanish Rice', 0.6158781), ('Rice Casseroles', 0.5451129), ('Shrimp and Grits', 0.5381528), ('Fried Rice', 0.533735), ('Rice Pilaf', 0.53004956), ('Apple Pie', 0.6685284), ('Slab Pie', 0.6171397), ('Pecan Pie', 0.59832394), ('Pie Crusts', 0.59374917), ('Rhubarb Pie', 0.5916555), ('Chicken Parmesan', 0.5195969), ('Stuffed Peppers', 0.5150045), ('LuncMacaroni and Cheese', 0.4865054), ('Truffles', 0.4843176), ('Beef Tenderloin', 0.48340762), ('Tuna Salads', 0.5414821), ('Taco Salads', 0.4989306), ('Chicken Salads', 0.49761587), ('Salads', 0.49466586), ('Fruit Salads', 0.49006802), ('Apple Pie', 0.6784862), ('Pie Crusts', 0.6154899), ('Pecan Pie', 0.60518575), (\"Shepherd's Pie\", 0.5849865), ('Rhubarb Pie', 0.5742655), ('Green Salads', 0.74158454), ('Fruit Salads', 0.6684198), ('Salad Dressings', 0.6492334), ('Broccoli Salads', 0.6094873), ('Tomato Salads', 0.59773093)]\n",
      "Top Tags = ['Green Salads', 'Apple Pie', 'Brownies']\n",
      "Provide a three-word essence of recipes featuring: Green Salads, Apple Pie, and Brownies.\n",
      "Generating title from the model...\n",
      "Decoding the generated title...\n",
      "Generated Title: Create a recipe for a green salad with a green dressing, apple pie, and brownie topping.\n",
      "\n",
      "Create a recipe for a brownie with a green dressing, apple pie, and brownie topping.\n",
      "\n",
      "Create a recipe for a brownie with a green dressing, apple pie, and brownie topping.\n",
      "\n",
      "Create a recipe for a green salad with a green\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load GPT-2 model and tokenizer\n",
    "model_name = \"gpt2-medium\"\n",
    "print(f\"Loading the {model_name} model and tokenizer...\")\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Rank tags based on their scores\n",
    "def rank_tags(tags_data):\n",
    "    tag_scores = defaultdict(float)\n",
    "    tag_counts = defaultdict(int)\n",
    "    \n",
    "    for tag, score in tags_data:\n",
    "        tag_scores[tag] += score\n",
    "        tag_counts[tag] += 1\n",
    "        \n",
    "    # Average the scores\n",
    "    for tag in tag_scores:\n",
    "        tag_scores[tag] /= tag_counts[tag]\n",
    "        \n",
    "    # Sort tags based on scores\n",
    "    sorted_tags = sorted(tag_scores.keys(), key=lambda x: tag_scores[x], reverse=True)\n",
    "    \n",
    "    return sorted_tags[:3]  # Take top 3 tags\n",
    "\n",
    "# Function to generate title based on tags\n",
    "def generate_title(tags):\n",
    "    top_tags = rank_tags(tags)\n",
    "    \n",
    "    print(f\"Top Tags = {top_tags}\")\n",
    "    \n",
    "    # Refined prompt\n",
    "    prompt = f\"Provide a three-word essence of recipes featuring: {', '.join(top_tags[:-1])}, and {top_tags[-1]}.\"\n",
    "    print(prompt)\n",
    "    \n",
    "    print(\"Generating title from the model...\")\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids, \n",
    "                                max_length=100, \n",
    "                                temperature=1.2, \n",
    "                                top_k=30, \n",
    "                                top_p=0.95, \n",
    "                                num_return_sequences=1)\n",
    "    \n",
    "    # Decode the generated text\n",
    "    print(\"Decoding the generated title...\")\n",
    "    generated_title_full = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    generated_title = generated_title_full[len(prompt):].strip()\n",
    "    \n",
    "    return generated_title\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"examples.csv\")\n",
    "\n",
    "def process_row(row):\n",
    "    # Extract classes and scores\n",
    "    classes = row[\"Predicted Classes\"].split(\", \")\n",
    "    scores = list(map(float, row[\"Raw Similarity Scores\"].split(\", \")))\n",
    "    \n",
    "    # Pair classes with scores\n",
    "    tags_scores = list(zip(classes, scores))\n",
    "    \n",
    "    return tags_scores\n",
    "\n",
    "# Process the DataFrame to get paired classes and scores\n",
    "df[\"Tags\"] = df.apply(process_row, axis=1)\n",
    "\n",
    "# Randomly select 10 recipes\n",
    "selected_recipes = df.sample(10)\n",
    "\n",
    "# Aggregate tags from selected recipes\n",
    "all_tags = []\n",
    "for _, row in selected_recipes.iterrows():\n",
    "    all_tags.extend(row[\"Tags\"])\n",
    "\n",
    "# Generate title using aggregated tags\n",
    "print(\"\\nGenerating title for aggregated tags from 10 recipes:\")\n",
    "print(f\"All tags =  {all_tags}\")\n",
    "title = generate_title(all_tags)\n",
    "print(f\"Generated Title: {title}\")\n",
    "print(\"---------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9ad035-103b-41aa-a519-8f440436b4af",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6386aec-2031-4173-8250-d209e5b565e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the facebook/bart-large-cnn model and tokenizer...\n",
      "\n",
      "Generating title for aggregated tags from 10 recipes:\n",
      "All tags =  [('Pot Roast', 0.5545994), ('Beef Stews', 0.50860476), ('Beef Recipes', 0.5063336), ('Ground Turkey', 0.4858606), ('Stuffed Peppers', 0.484233), ('Truffles', 0.6374452), ('Chocolate Cakes', 0.44036984), ('Chocolate Fudge', 0.43471563), ('Coffee Cakes', 0.40213692), ('Baked Beans', 0.39306107), ('Chocolate Fudge', 0.5347718), ('Creme Brulee', 0.5260148), ('Cheese Fondue', 0.5215686), ('Key Lime Pie', 0.50871575), ('Truffles', 0.5070548), ('Cheesecakes', 0.5782757), ('Strawberry Shortcakes', 0.51190835), ('Cheese Fondue', 0.5086514), ('Strawberry Pie', 0.48128277), ('Cherry Pie', 0.4651184), ('Pancit', 0.5637951), ('Lasagna', 0.55923486), ('Pasta Carbonara', 0.5531048), ('Fettuccini', 0.54990935), ('Panini', 0.5405712), ('Pasta Salads', 0.62125194), ('Chicken Salads', 0.587828), ('Broccoli Salads', 0.5715915), ('Fruit Salads', 0.5669699), ('Potato Salads', 0.55193263), ('Cherry Pie', 0.46061802), ('Apple Pie', 0.45881546), ('Strawberry Pie', 0.4328868), ('Fruitcakes', 0.42915797), ('Blueberry Pie', 0.41354588), ('Vegetable Side Dishes', 0.50633514), ('Beef Stews', 0.49842006), ('Pork Shoulder', 0.48536634), ('Corned Beef', 0.47231966), ('Beef Stroganoff', 0.46621105), ('Pasta Salads', 0.64517796), ('Broccoli Salads', 0.6212965), ('Green Salads', 0.6122006), ('Chicken Salads', 0.6043484), ('Salads', 0.59683204), ('Ice Cream', 0.5993972), ('Strawberry Shortcakes', 0.53053826), ('Desserts', 0.52961546), ('Strawberry Pie', 0.5263274), ('Creme Brulee', 0.5016248)]\n",
      "Top Tags = ['Pasta Salads', 'Green Salads', 'Ice Cream']\n",
      "Recipes highlighting: Pasta Salads, Green Salads, and Ice Cream. Describe in a few words.\n",
      "Generated Title: Recipes highlighting: Pasta Salads, Green Salads and Ice Cream. Describe in a few words.\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "print(f\"Loading the {model_name} model and tokenizer...\")\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "def rank_tags(tags_data):\n",
    "    tag_scores = defaultdict(float)\n",
    "    tag_counts = defaultdict(int)\n",
    "    \n",
    "    for tag, score in tags_data:\n",
    "        tag_scores[tag] += score\n",
    "        tag_counts[tag] += 1\n",
    "        \n",
    "    for tag in tag_scores:\n",
    "        tag_scores[tag] /= tag_counts[tag]\n",
    "        \n",
    "    sorted_tags = sorted(tag_scores.keys(), key=lambda x: tag_scores[x], reverse=True)\n",
    "    \n",
    "    return sorted_tags[:3]\n",
    "\n",
    "def generate_title(tags):\n",
    "    top_tags = rank_tags(tags)\n",
    "    print(f\"Top Tags = {top_tags}\")\n",
    "    prompt = f\"Recipes highlighting: {', '.join(top_tags[:-1])}, and {top_tags[-1]}. Describe in a few words.\"\n",
    "    print(prompt)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).input_ids\n",
    "        summary_ids = model.generate(input_ids, \n",
    "                                     max_length=100,\n",
    "                                     min_length=10,\n",
    "                                     num_beams=7, \n",
    "                                     length_penalty=1.5, \n",
    "                                     early_stopping=True,\n",
    "                                     temperature=0.9,\n",
    "                                     top_k=30,\n",
    "                                     top_p=0.95)\n",
    "    \n",
    "    generated_title = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return generated_title\n",
    "\n",
    "df = pd.read_csv(\"examples.csv\")\n",
    "\n",
    "def process_row(row):\n",
    "    classes = row[\"Predicted Classes\"].split(\", \")\n",
    "    scores = list(map(float, row[\"Raw Similarity Scores\"].split(\", \")))\n",
    "    tags_scores = list(zip(classes, scores))\n",
    "    return tags_scores\n",
    "\n",
    "df[\"Tags\"] = df.apply(process_row, axis=1)\n",
    "selected_recipes = df.sample(10)\n",
    "\n",
    "all_tags = []\n",
    "for _, row in selected_recipes.iterrows():\n",
    "    all_tags.extend(row[\"Tags\"])\n",
    "\n",
    "print(\"\\nGenerating title for aggregated tags from 10 recipes:\")\n",
    "print(f\"All tags =  {all_tags}\")\n",
    "title = generate_title(all_tags)\n",
    "print(f\"Generated Title: {title}\")\n",
    "print(\"---------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b63b161-e6cb-48c5-be97-80dd5c3864e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
